# ğŸ¯ Interview Predictor - AI-Powered Interview Analysis

Real-time interview performance prediction using speech-to-text, NLP sentiment analysis, and machine learning.

![Demo](static/demo.gif)

## âœ¨ Features

- **Multi-Model ASR**: Supports Whisper Tiny, Base, Small, and Medium models
- **Real-time Analysis**: Live progress tracking with SSE
- **Component Scoring**: Sentiment, toxicity, competency, and keyword analysis
- **Performance Timeline**: Visualize performance across interview duration
- **AI Feedback**: Gemini-powered actionable feedback generation
- **GPU Acceleration**: CUDA support for faster processing

## ğŸš€ Quick Start (Local)

### Prerequisites

- Ubuntu 22.04+ (or similar Debian-based system)
- Python 3.11+
- NVIDIA GPU with CUDA 12.1+ (optional, for acceleration)
- 8GB+ RAM
- 20GB+ disk space

### One-Command Install
```bash
sudo bash install_local.sh
```

### Manual Setup

See [README_LOCAL.md](README_LOCAL.md) for detailed local deployment instructions.

## ğŸ³ Docker Deployment (Recommended)

### Quick Start
```bash
# Clone repository
git clone <your-repo-url>
cd interview-predictor

# Create .env file
echo "GEMINI_API_KEY=your-key-here" > .env

# Start with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### Docker Configuration

- **Port**: 8080 (configurable in `docker-compose.yml`)
- **GPU Support**: Automatically detected
- **Volume**: Data persists in `./data`

## ğŸ“Š Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚ (Streamlit/HTML)
â”‚  (Browser)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚ (API Server)
â”‚   Backend   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Core Components               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ASR          â”‚ Faster-Whisper       â”‚
â”‚ NLP          â”‚ Transformers         â”‚
â”‚ Scoring      â”‚ Ensemble ML          â”‚
â”‚ Timeline     â”‚ Temporal Analysis    â”‚
â”‚ Feedback     â”‚ Gemini API           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Testing
```bash
# Test audio analysis
curl -X POST http://localhost:8080/api/analyze-audio \
  -F "file=@sample.mp3" \
  -F "model_size=base"

# Test text analysis
curl -X POST http://localhost:8080/api/analyze-text \
  -F "text=I have 5 years of experience in Python"

# Health check
curl http://localhost:8080/health
```

## ğŸ“ˆ Component Scoring

| Component | Weight | Description |
|-----------|--------|-------------|
| Sentiment | 25% | Positive vs negative emotional tone |
| Toxicity | 25% | Professional language (inverted toxicity) |
| Competency | 30% | Technical skills and role fit |
| Keywords | 20% | Interview signals and professionalism |

**Overall Score Ranges**:
- **70-100%**: Strong (High confidence)
- **50-69%**: Moderate (Medium confidence)
- **0-49%**: Weak (Low confidence)

## ğŸ› ï¸ Development

### Project Structure
```
interview-predictor/
â”œâ”€â”€ app.py                      # FastAPI main application
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html             # Web interface
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ asr_processor.py       # Audio transcription
â”‚   â”œâ”€â”€ nlp_analyzer.py        # Sentiment/toxicity analysis
â”‚   â”œâ”€â”€ ensemble_scorer.py     # Score calculation
â”‚   â”œâ”€â”€ timeline_analyzer.py   # Performance timeline
â”‚   â””â”€â”€ llm_feedback.py        # AI feedback generation
â”œâ”€â”€ requirements-local.txt      # Python dependencies
â”œâ”€â”€ Dockerfile                 # Container definition
â”œâ”€â”€ docker-compose.yml         # Docker orchestration
â”œâ”€â”€ install_local.sh           # Local installation script
â””â”€â”€ start_local.sh             # Local startup script
```

### Key Dependencies

- **FastAPI**: Modern web framework
- **PyTorch**: Deep learning (CUDA 12.1)
- **Transformers**: NLP models
- **Faster-Whisper**: Efficient ASR
- **Gemini API**: AI feedback generation

## ğŸ”§ Configuration

### Environment Variables

Create `.env` file:
```bash
GEMINI_API_KEY=your-api-key-here
```

### Model Selection

| Model | Size | Accuracy | Speed | Best For |
|-------|------|----------|-------|----------|
| Tiny | 39M | â­â­â­ | 3-5 min/30min | Quick demos |
| Base | 74M | â­â­â­â­ | 5-8 min/30min | Balanced (recommended) |
| Small | 244M | â­â­â­â­â­ | 10-15 min/30min | Higher accuracy |
| Medium | 769M | â­â­â­â­â­ | 20-30 min/30min | Maximum accuracy |

## ğŸ“ API Documentation

Once running, visit:
- **Interactive Docs**: http://localhost:8080/docs
- **ReDoc**: http://localhost:8080/redoc

### Key Endpoints

- `POST /api/analyze-audio` - Analyze audio file
- `POST /api/analyze-text` - Analyze text input
- `POST /api/generate-feedback` - Generate AI feedback
- `GET /api/model-info` - Get model information
- `GET /api/progress` - SSE progress stream
- `GET /health` - Health check

## âš ï¸ Known Issues & Solutions

### NumPy Version
**Issue**: ImportError with transformers
**Solution**: Ensure `numpy<2.0` (critical for transformers 4.44.2)

### PyTorch Version Mismatch
**Issue**: torchvision::nms errors
**Solution**: Use PyTorch 2.5.1 with torchvision 0.20.1

### GPU Not Detected
**Issue**: CUDA not available
**Solution**: Verify NVIDIA drivers and CUDA 12.1+ installation

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file

## ğŸ™ Acknowledgments

- **OpenAI Whisper**: Speech recognition
- **Hugging Face**: NLP models
- **Anthropic**: Claude AI assistance
- **Google Gemini**: Feedback generation

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Built with â¤ï¸ for better interview experiences**
